{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal is to take out-of-the-box models and apply them to different datasets. This project is awesome for 3 main reasons:\n",
    "\n",
    "# First, you’ll build intuition for model-to-problem fit. Which models are robust to missing data? Which models handle categorical features well? Yes, you can dig through textbooks to find the answers, but you’ll learn better by seeing it in action.\n",
    "\n",
    "# Second, this project will teach you the invaluable skill of prototyping models quickly. In the real world, it’s often difficult to know which model will perform best without simply trying them.\n",
    "\n",
    "# Finally, this exercise helps you master the workflow of model building. For example, you’ll get to practice…\n",
    "\n",
    "# Importing data\n",
    "# Cleaning data\n",
    "# Splitting it into train/test or cross-validation sets\n",
    "# Pre-processing\n",
    "# Transformations\n",
    "# Feature engineering\n",
    "# Because you’ll use out-of-the-box models, you’ll have the chance to focus on honing these critical steps.\n",
    "\n",
    "#Questions to ask - predict market value or popularity based on factors such as teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "with open('epldata_final.csv', 'r') as csvfile:\n",
    "         reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "\n",
    "\n",
    "players = pd.read_csv('epldata_final.csv')\n",
    "players = [players['age'], players['age']]\n",
    "\n",
    "# print(housing.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'hist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a0ea82368ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# using matplotlib you can show histogram data and outputs for regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'hist'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# using matplotlib you can show histogram data and outputs for regions\n",
    "players.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n",
    "\n",
    "# General info about a data set\n",
    "print(players.info())\n",
    "\n",
    "'''\n",
    "find specific column numbers \n",
    "print(housing[\"ocean_proximity\"].value_counts())\n",
    "'''\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data - This is done with the csv reader above\n",
    "# The jobs now are to: \n",
    "# Cleaning data - checking for null values and values that are highly correlated to delete\n",
    "\n",
    "# Splitting it into train/test or cross-validation sets - Done see below\n",
    "\n",
    "# Pre-processing - To make sure the data being used is compatible\n",
    "# Transformations \n",
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a169b9809461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train +\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-a169b9809461>\u001b[0m in \u001b[0;36msplit_train_test\u001b[0;34m(data, test_ratio)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_set_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_set_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "\n",
    "train_set, test_set = split_train_test(players, 0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389    52\n",
      "32     52\n",
      "136    64\n",
      "51     60\n",
      "87     50\n",
      "275    54\n",
      "49     48\n",
      "209    50\n",
      "331    68\n",
      "212    58\n",
      "66     46\n",
      "400    64\n",
      "83     58\n",
      "244    62\n",
      "254    40\n",
      "401    60\n",
      "116    58\n",
      "334    58\n",
      "175    42\n",
      "369    54\n",
      "200    62\n",
      "265    58\n",
      "336    72\n",
      "255    52\n",
      "353    64\n",
      "440    48\n",
      "385    48\n",
      "391    42\n",
      "231    36\n",
      "217    62\n",
      "       ..\n",
      "411    56\n",
      "206    60\n",
      "359    58\n",
      "412    42\n",
      "323    44\n",
      "450    60\n",
      "304    44\n",
      "146    72\n",
      "278    70\n",
      "327    42\n",
      "150    54\n",
      "394    44\n",
      "370    48\n",
      "257    54\n",
      "318    60\n",
      "449    56\n",
      "60     48\n",
      "409    48\n",
      "415    60\n",
      "204    56\n",
      "417    52\n",
      "390    54\n",
      "222    46\n",
      "288    54\n",
      "167    60\n",
      "266    54\n",
      "3      56\n",
      "425    54\n",
      "219    52\n",
      "21     56\n",
      "Name: age, Length: 369, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "# # X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "# #               [4, 2], [4, 4], [4, 0]])\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(players)\n",
    "# kmeans.labels_\n",
    "\n",
    "# # kmeans.predict([[0, 0], [4, 4]])\n",
    "\n",
    "# # kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[52. 52. 64. 60. 50. 54. 48. 50. 68. 58. 46. 64. 58. 62. 40. 60. 58. 58.\n 42. 54. 62. 58. 72. 52. 64. 48. 48. 42. 36. 62. 42. 58. 48. 40. 64. 48.\n 50. 54. 46. 54. 54. 60. 48. 58. 50. 60. 62. 58. 52. 58. 52. 52. 42. 52.\n 42. 56. 54. 60. 60. 60. 42. 54. 54. 66. 60. 56. 44. 54. 52. 54. 60. 66.\n 50. 56. 42. 42. 44. 68. 50. 50. 50. 58. 54. 52. 46. 44. 50. 56. 64. 40.\n 52. 58. 72. 56. 50. 58. 62. 52. 54. 58. 62. 68. 58. 48. 54. 46. 50. 56.\n 52. 52. 50. 68. 52. 50. 54. 62. 54. 52. 62. 52. 50. 44. 58. 64. 44. 50.\n 38. 54. 40. 44. 54. 54. 46. 52. 38. 50. 46. 66. 64. 48. 60. 46. 50. 42.\n 46. 60. 64. 44. 50. 62. 64. 68. 56. 48. 38. 74. 44. 54. 38. 62. 60. 50.\n 52. 56. 52. 54. 46. 52. 52. 52. 46. 68. 50. 48. 58. 56. 56. 56. 52. 52.\n 46. 62. 66. 38. 44. 56. 52. 64. 48. 64. 42. 56. 42. 48. 42. 46. 56. 38.\n 68. 64. 66. 54. 42. 58. 62. 60. 40. 46. 62. 54. 56. 56. 50. 54. 50. 52.\n 60. 46. 42. 48. 44. 64. 70. 48. 50. 54. 52. 66. 72. 52. 50. 48. 42. 66.\n 56. 64. 68. 50. 76. 62. 60. 50. 54. 56. 34. 48. 46. 62. 52. 66. 54. 50.\n 46. 48. 52. 42. 74. 60. 52. 58. 54. 48. 64. 60. 58. 54. 54. 60. 68. 50.\n 58. 40. 52. 44. 54. 54. 50. 58. 54. 46. 64. 56. 52. 62. 58. 62. 60. 52.\n 62. 42. 54. 48. 58. 54. 50. 50. 58. 50. 60. 40. 44. 52. 48. 68. 48. 46.\n 46. 40. 68. 46. 62. 60. 52. 42. 42. 62. 54. 54. 62. 64. 52. 40. 40. 60.\n 56. 64. 58. 48. 56. 50. 52. 54. 68. 54. 56. 60. 56. 50. 64. 56. 60. 58.\n 42. 44. 60. 44. 72. 70. 42. 54. 44. 48. 54. 60. 56. 48. 48. 60. 56. 52.\n 54. 46. 54. 60. 54. 56. 54. 52. 56.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ad066a93cb5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Applying transformer to training dataPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(X_train_scaled.mean(axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy, warn_on_dtype=True,\n\u001b[0;32m--> 681\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[52. 52. 64. 60. 50. 54. 48. 50. 68. 58. 46. 64. 58. 62. 40. 60. 58. 58.\n 42. 54. 62. 58. 72. 52. 64. 48. 48. 42. 36. 62. 42. 58. 48. 40. 64. 48.\n 50. 54. 46. 54. 54. 60. 48. 58. 50. 60. 62. 58. 52. 58. 52. 52. 42. 52.\n 42. 56. 54. 60. 60. 60. 42. 54. 54. 66. 60. 56. 44. 54. 52. 54. 60. 66.\n 50. 56. 42. 42. 44. 68. 50. 50. 50. 58. 54. 52. 46. 44. 50. 56. 64. 40.\n 52. 58. 72. 56. 50. 58. 62. 52. 54. 58. 62. 68. 58. 48. 54. 46. 50. 56.\n 52. 52. 50. 68. 52. 50. 54. 62. 54. 52. 62. 52. 50. 44. 58. 64. 44. 50.\n 38. 54. 40. 44. 54. 54. 46. 52. 38. 50. 46. 66. 64. 48. 60. 46. 50. 42.\n 46. 60. 64. 44. 50. 62. 64. 68. 56. 48. 38. 74. 44. 54. 38. 62. 60. 50.\n 52. 56. 52. 54. 46. 52. 52. 52. 46. 68. 50. 48. 58. 56. 56. 56. 52. 52.\n 46. 62. 66. 38. 44. 56. 52. 64. 48. 64. 42. 56. 42. 48. 42. 46. 56. 38.\n 68. 64. 66. 54. 42. 58. 62. 60. 40. 46. 62. 54. 56. 56. 50. 54. 50. 52.\n 60. 46. 42. 48. 44. 64. 70. 48. 50. 54. 52. 66. 72. 52. 50. 48. 42. 66.\n 56. 64. 68. 50. 76. 62. 60. 50. 54. 56. 34. 48. 46. 62. 52. 66. 54. 50.\n 46. 48. 52. 42. 74. 60. 52. 58. 54. 48. 64. 60. 58. 54. 54. 60. 68. 50.\n 58. 40. 52. 44. 54. 54. 50. 58. 54. 46. 64. 56. 52. 62. 58. 62. 60. 52.\n 62. 42. 54. 48. 58. 54. 50. 50. 58. 50. 60. 40. 44. 52. 48. 68. 48. 46.\n 46. 40. 68. 46. 62. 60. 52. 42. 42. 62. 54. 54. 62. 64. 52. 40. 40. 60.\n 56. 64. 58. 48. 56. 50. 52. 54. 68. 54. 56. 60. 56. 50. 64. 56. 60. 58.\n 42. 44. 60. 44. 72. 70. 42. 54. 44. 48. 54. 60. 56. 48. 48. 60. 56. 52.\n 54. 46. 54. 60. 54. 56. 54. 52. 56.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler().fit(players)\n",
    "# Applying transformer to training dataPython\n",
    "\n",
    "X_train_scaled = scaler.transform(train_set)\n",
    " \n",
    "# print(X_train_scaled.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fot the above clustering algorithm you should sort the features as below\n",
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn#step-5\n",
    "\n",
    "# To do:\n",
    "# numpy arrays figure out and use to create 2d array\n",
    "# remove feature with letter resave features in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
