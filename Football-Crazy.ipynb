{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal is to take out-of-the-box models and apply them to different datasets. This project is awesome for 3 main reasons:\n",
    "\n",
    "# First, you’ll build intuition for model-to-problem fit. Which models are robust to missing data? Which models handle categorical features well? Yes, you can dig through textbooks to find the answers, but you’ll learn better by seeing it in action.\n",
    "\n",
    "# Second, this project will teach you the invaluable skill of prototyping models quickly. In the real world, it’s often difficult to know which model will perform best without simply trying them.\n",
    "\n",
    "# Finally, this exercise helps you master the workflow of model building. For example, you’ll get to practice…\n",
    "\n",
    "# Importing data\n",
    "# Cleaning data\n",
    "# Splitting it into train/test or cross-validation sets\n",
    "# Pre-processing\n",
    "# Transformations\n",
    "# Feature engineering\n",
    "# Because you’ll use out-of-the-box models, you’ll have the chance to focus on honing these critical steps.\n",
    "\n",
    "#Questions to ask - predict market value or popularity based on factors such as teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "with open('epldata_final.csv', 'r') as csvfile:\n",
    "         reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "\n",
    "\n",
    "players = pd.read_csv('epldata_final.csv')\n",
    "players = [players['age'], players['age']]\n",
    "\n",
    "# print(housing.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>club</th>\n",
       "      <th>age</th>\n",
       "      <th>position</th>\n",
       "      <th>position_cat</th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_value</th>\n",
       "      <th>fpl_sel</th>\n",
       "      <th>fpl_points</th>\n",
       "      <th>region</th>\n",
       "      <th>nationality</th>\n",
       "      <th>new_foreign</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>club_id</th>\n",
       "      <th>big_club</th>\n",
       "      <th>new_signing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexis Sanchez</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>LW</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4329</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.10%</td>\n",
       "      <td>264</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chile</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mesut Ozil</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>AM</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4395</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.60%</td>\n",
       "      <td>167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petr Cech</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>35</td>\n",
       "      <td>GK</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1529</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.90%</td>\n",
       "      <td>134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theo Walcott</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>RW</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2393</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50%</td>\n",
       "      <td>122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laurent Koscielny</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>31</td>\n",
       "      <td>CB</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>912</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name     club  age position  position_cat  market_value  \\\n",
       "0     Alexis Sanchez  Arsenal   28       LW             1          65.0   \n",
       "1         Mesut Ozil  Arsenal   28       AM             1          50.0   \n",
       "2          Petr Cech  Arsenal   35       GK             4           7.0   \n",
       "3       Theo Walcott  Arsenal   28       RW             1          20.0   \n",
       "4  Laurent Koscielny  Arsenal   31       CB             3          22.0   \n",
       "\n",
       "   page_views  fpl_value fpl_sel  fpl_points  region     nationality  \\\n",
       "0        4329       12.0  17.10%         264     3.0           Chile   \n",
       "1        4395        9.5   5.60%         167     2.0         Germany   \n",
       "2        1529        5.5   5.90%         134     2.0  Czech Republic   \n",
       "3        2393        7.5   1.50%         122     1.0         England   \n",
       "4         912        6.0   0.70%         121     2.0          France   \n",
       "\n",
       "   new_foreign  age_cat  club_id  big_club  new_signing  \n",
       "0            0        4        1         1            0  \n",
       "1            0        4        1         1            0  \n",
       "2            0        6        1         1            0  \n",
       "3            0        4        1         1            0  \n",
       "4            0        4        1         1            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_path = 'epldata_final.csv'\n",
    "\n",
    "footballers = pd.read_csv(data_path)\n",
    "# visualise data\n",
    "footballers.head()\n",
    "# Below is Visual of age on market value\n",
    "# footballers[:24*10].plot(y='market_value', x='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>position_cat</th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_value</th>\n",
       "      <th>fpl_points</th>\n",
       "      <th>region</th>\n",
       "      <th>new_foreign</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>club_id</th>\n",
       "      <th>big_club</th>\n",
       "      <th>new_signing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4329</td>\n",
       "      <td>12.0</td>\n",
       "      <td>264</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4395</td>\n",
       "      <td>9.5</td>\n",
       "      <td>167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1529</td>\n",
       "      <td>5.5</td>\n",
       "      <td>134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2393</td>\n",
       "      <td>7.5</td>\n",
       "      <td>122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>912</td>\n",
       "      <td>6.0</td>\n",
       "      <td>121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  position_cat  market_value  page_views  fpl_value  fpl_points  region  \\\n",
       "0   28             1          65.0        4329       12.0         264     3.0   \n",
       "1   28             1          50.0        4395        9.5         167     2.0   \n",
       "2   35             4           7.0        1529        5.5         134     2.0   \n",
       "3   28             1          20.0        2393        7.5         122     1.0   \n",
       "4   31             3          22.0         912        6.0         121     2.0   \n",
       "\n",
       "   new_foreign  age_cat  club_id  big_club  new_signing  \n",
       "0            0        4        1         1            0  \n",
       "1            0        4        1         1            0  \n",
       "2            0        6        1         1            0  \n",
       "3            0        4        1         1            0  \n",
       "4            0        4        1         1            0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEAN DATA\n",
    "# Why do we use dummy data?\n",
    "dummy_fields = ['club', 'position', 'nationality', 'name', 'fpl_sel']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(footballers[each], prefix=each, drop_first=False)\n",
    "    footballers = pd.concat([footballers, dummies], axis=1)\n",
    "\n",
    "# dropping fields of no use to us to prep data    \n",
    "fields_to_drop = ['club', 'position', 'nationality', 'name', 'fpl_sel']\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values - why do we do this???\n",
    "quant_features = ['market_value', 'position_cat', 'age', 'page_views', 'fpl_points', 'big_club']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data - This is done with the csv reader above\n",
    "# The jobs now are to: \n",
    "# Cleaning data - checking for null values and values that are highly correlated to delete\n",
    "\n",
    "# Splitting it into train/test or cross-validation sets - Done see below\n",
    "\n",
    "# Pre-processing - To make sure the data being used is compatible\n",
    "# Transformations \n",
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 train + 92 test\n"
     ]
    }
   ],
   "source": [
    "# Data - what has happened to the data as in negative values etc\n",
    "import numpy as np\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "\n",
    "train_features, test_features = split_train_test(data, 0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  position_cat  market_value  page_views  fpl_value  fpl_points  \\\n",
      "75   0.049276     -1.179971     -0.531274   -0.508450        6.0    1.199038   \n",
      "17   1.311300     -0.180032      0.080601    0.192340        7.0   -0.363644   \n",
      "254 -1.717556     -1.179971      0.325351    0.963960        7.0   -0.100059   \n",
      "115 -0.203128      0.819906     -0.164149   -0.257325        5.5    0.766005   \n",
      "207  0.806490     -1.179971     -0.408899   -0.313130        5.0   -0.627229   \n",
      "111 -1.212747     -0.180032      0.406935    0.265316        5.0   -1.079089   \n",
      "392 -0.455533     -1.179971      1.141185   -0.098493        6.5   -0.551919   \n",
      "346 -0.960342     -1.179971      0.325351    0.082875        6.0   -0.589574   \n",
      "227  0.806490     -0.180032     -0.327316    0.251365        4.5   -0.194197   \n",
      "80   0.049276     -1.179971     -0.694441   -0.511669        5.5    0.445938   \n",
      "251 -1.717556     -1.179971      1.549101    3.745656       10.5    0.182353   \n",
      "196  0.554086     -1.179971      1.141185    0.877032        7.0    0.483593   \n",
      "107 -1.212747      0.819906      0.325351   -0.043761        5.5   -0.796677   \n",
      "322 -0.455533     -1.179971      0.325351    1.339575        7.0   -0.363644   \n",
      "387  0.806490     -0.180032      0.570101    0.426294        5.0    0.351801   \n",
      "267  0.049276     -0.180032      1.549101    0.900642        5.5    0.747178   \n",
      "257  0.049276     -0.180032     -0.245732   -0.261617        4.5   -0.834332   \n",
      "120  0.049276      0.819906     -0.490482   -0.654403        5.0    0.540075   \n",
      "188 -1.212747     -1.179971     -0.449691   -0.759575        6.0   -1.079089   \n",
      "25   1.311300      0.819906     -0.408899   -0.066298        5.0   -1.060262   \n",
      "10  -0.707938     -0.180032      1.957018    1.128157        5.5    0.521248   \n",
      "388 -0.960342     -1.179971      0.162185    0.398391        7.5   -0.043577   \n",
      "244  1.058895     -1.179971      1.549101    0.719274        8.0    1.368485   \n",
      "224 -1.212747     -1.179971      0.080601    0.352244        7.5    0.728350   \n",
      "411  0.301681      0.819906     -0.572066   -0.682306        4.5   -0.495437   \n",
      "78   1.058895      0.819906     -0.776024   -0.656549        4.5    0.634213   \n",
      "3    0.301681     -1.179971      0.733268    1.748458        7.5    1.217865   \n",
      "57   2.320919     -1.179971     -0.857607   -0.588939        4.5   -1.079089   \n",
      "349  1.058895     -0.180032     -0.653649   -0.324935        5.0   -0.796677   \n",
      "434  0.301681     -1.179971     -0.694441    0.002386        5.0   -0.100059   \n",
      "..        ...           ...           ...         ...        ...         ...   \n",
      "272  0.049276      0.819906      0.080601    0.940350        5.5    0.238836   \n",
      "14  -0.203128     -0.180032      0.325351   -0.230495        4.5   -0.100059   \n",
      "427  1.058895     -0.180032     -0.490482   -0.564256        5.5    0.502420   \n",
      "328 -1.465152      0.819906     -0.857607   -0.810015        4.5   -1.079089   \n",
      "247  1.058895      0.819906     -0.082566   -0.140347        5.5    0.709523   \n",
      "233 -2.474770     -1.179971     -0.776024    0.512149        4.5   -0.984952   \n",
      "185  0.049276     -1.179971     -0.490482   -0.554597        5.0   -1.079089   \n",
      "50  -0.960342      0.819906     -0.735232   -0.500938        4.0   -1.003779   \n",
      "177 -0.455533     -0.180032     -0.878003   -0.732746        4.5   -1.079089   \n",
      "249  1.311300     -0.180032      0.570101   -0.181128        5.0    0.389456   \n",
      "432  0.806490     -0.180032     -0.572066   -0.642598        4.5   -0.062404   \n",
      "169  2.068514      0.819906     -0.857607   -0.744551        4.0   -1.079089   \n",
      "37  -0.707938     -1.179971     -0.082566   -0.253032        6.0    0.577730   \n",
      "32  -0.203128      0.819906     -0.490482   -0.622208        5.0    1.029590   \n",
      "406  1.311300     -0.180032     -0.694441   -0.565329        4.5   -0.175369   \n",
      "381  0.806490      0.819906      1.385935   -0.271276        6.0    1.293175   \n",
      "390  0.049276     -0.180032      0.733268    0.427367        5.5   -0.269507   \n",
      "130  0.049276      0.819906     -0.408899   -0.620061        4.5   -0.966124   \n",
      "395 -0.707938      0.819906     -0.327316   -0.438693        4.5   -1.041434   \n",
      "456 -1.465152     -0.180032     -0.490482   -0.510596        4.5   -0.363644   \n",
      "121  0.301681      0.819906     -0.327316   -0.596451        4.5    0.332973   \n",
      "39   0.806490     -1.179971     -0.735232   -0.669428        5.0    0.125871   \n",
      "331  1.816109      1.819845     -0.816816   -0.304545        4.5    0.916625   \n",
      "345  1.311300      0.819906     -0.776024   -0.427961        4.5   -0.570747   \n",
      "448  1.563704      0.819906     -0.735232   -0.618988        4.5    0.220008   \n",
      "237 -0.455533     -1.179971      1.957018    0.379074        9.0   -1.079089   \n",
      "250  1.816109      1.819845     -0.245732   -0.351765        5.0    0.295318   \n",
      "450  0.806490      1.819845     -0.245732   -0.534206        4.5    0.125871   \n",
      "175 -1.465152     -0.180032     -0.857607   -0.651184        4.5   -1.079089   \n",
      "206  0.806490      0.819906     -0.816816   -0.492352        4.5   -0.570747   \n",
      "\n",
      "     region  new_foreign  age_cat  club_id  big_club  new_signing  \n",
      "75      2.0            0        3        4 -0.659690            0  \n",
      "17      2.0            0        5        1  1.512575            0  \n",
      "254     4.0            0        1       11  1.512575            0  \n",
      "115     2.0            0        3        6 -0.659690            0  \n",
      "207     2.0            0        4        9 -0.659690            0  \n",
      "111     2.0            1        2        5  1.512575            0  \n",
      "392     3.0            0        3       17  1.512575            0  \n",
      "346     1.0            0        2       15 -0.659690            0  \n",
      "227     3.0            0        4       10  1.512575            0  \n",
      "80      1.0            0        3        4 -0.659690            0  \n",
      "251     3.0            0        1       11  1.512575            1  \n",
      "196     4.0            0        4        9 -0.659690            1  \n",
      "107     2.0            0        2        5  1.512575            0  \n",
      "322     2.0            0        3       14 -0.659690            0  \n",
      "387     2.0            0        4       17  1.512575            0  \n",
      "267     2.0            0        3       12  1.512575            0  \n",
      "257     1.0            0        3       11  1.512575            0  \n",
      "120     1.0            0        3        6 -0.659690            0  \n",
      "188     NaN            0        2        8 -0.659690            0  \n",
      "25      2.0            0        5        1  1.512575            0  \n",
      "10      2.0            0        2        1  1.512575            0  \n",
      "388     2.0            0        2       17  1.512575            1  \n",
      "244     2.0            0        4       11  1.512575            0  \n",
      "224     2.0            0        2       10  1.512575            0  \n",
      "411     2.0            0        4       18 -0.659690            0  \n",
      "78      2.0            0        4        4 -0.659690            0  \n",
      "3       1.0            0        4        1  1.512575            0  \n",
      "57      3.0            0        6        3 -0.659690            0  \n",
      "349     2.0            0        4       15 -0.659690            0  \n",
      "434     2.0            0        4       19 -0.659690            1  \n",
      "..      ...          ...      ...      ...       ...          ...  \n",
      "272     2.0            0        3       12  1.512575            0  \n",
      "14      2.0            0        3        1  1.512575            0  \n",
      "427     2.0            0        4       19 -0.659690            0  \n",
      "328     2.0            1        1       14 -0.659690            0  \n",
      "247     2.0            0        4       11  1.512575            0  \n",
      "233     1.0            0        1       10  1.512575            0  \n",
      "185     3.0            0        3        8 -0.659690            0  \n",
      "50      4.0            0        2        2 -0.659690            0  \n",
      "177     1.0            0        3        8 -0.659690            0  \n",
      "249     3.0            0        5       11  1.512575            0  \n",
      "432     3.0            0        4       19 -0.659690            0  \n",
      "169     1.0            0        6        8 -0.659690            0  \n",
      "37      4.0            0        2        2 -0.659690            0  \n",
      "32      1.0            0        3        2 -0.659690            0  \n",
      "406     2.0            0        5       18 -0.659690            0  \n",
      "381     2.0            0        4       17  1.512575            0  \n",
      "390     2.0            0        3       17  1.512575            1  \n",
      "130     4.0            0        3        6 -0.659690            0  \n",
      "395     2.0            0        2       17  1.512575            0  \n",
      "456     2.0            0        1       20 -0.659690            1  \n",
      "121     1.0            0        4        6 -0.659690            1  \n",
      "39      1.0            0        4        2 -0.659690            0  \n",
      "331     1.0            0        6       15 -0.659690            1  \n",
      "345     2.0            0        5       15 -0.659690            0  \n",
      "448     2.0            0        5       20 -0.659690            0  \n",
      "237     4.0            1        3       10  1.512575            0  \n",
      "250     3.0            0        6       11  1.512575            1  \n",
      "450     2.0            0        4       20 -0.659690            0  \n",
      "175     2.0            0        1        8 -0.659690            0  \n",
      "206     4.0            0        4        9 -0.659690            0  \n",
      "\n",
      "[369 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  position_cat  market_value  page_views  fpl_value  fpl_points  \\\n",
      "265  0.554086     -1.179971      1.549101    1.627188        7.0    0.841315   \n",
      "412 -1.465152     -1.179971     -0.572066   -0.310984        5.5   -0.551919   \n",
      "320 -0.203128     -0.180032     -0.082566   -0.603963        4.5   -0.363644   \n",
      "332  0.301681      0.819906     -0.327316   -0.675867        5.0    0.860143   \n",
      "333  0.806490     -1.179971     -0.653649   -0.259471        5.0    0.860143   \n",
      "242 -1.212747     -1.179971      2.772852    1.406112        8.0    1.726208   \n",
      "410 -0.203128      0.819906     -0.449691   -0.629720        4.5   -0.420127   \n",
      "202 -1.465152     -1.179971     -0.164149   -0.183275        5.5    0.012906   \n",
      "327 -1.465152      0.819906     -0.878003   -0.762795        4.5   -1.079089   \n",
      "119  1.058895     -0.180032      0.325351   -0.330301        5.5    0.634213   \n",
      "306  0.554086      1.819845      0.325351   -0.231568        5.0    1.443795   \n",
      "460  0.049276     -1.179971     -0.082566   -0.590012        5.5   -0.853159   \n",
      "163  0.049276      0.819906     -0.735232   -0.741331        4.5   -1.079089   \n",
      "149  0.301681     -1.179971      0.733268    0.141900        6.5   -0.231852   \n",
      "241  0.554086     -1.179971      4.404519    3.522433       11.5    2.215722   \n",
      "223 -0.455533      0.819906      1.141185    0.589418        5.5    0.747178   \n",
      "418 -0.455533     -1.179971     -0.449691   -0.643671        5.0   -1.079089   \n",
      "335 -0.455533     -1.179971      0.325351    0.253511        6.0    0.427110   \n",
      "103  0.301681     -0.180032      1.957018    0.137607        5.0    0.897798   \n",
      "362 -0.455533     -1.179971     -0.286524   -0.094201        5.0   -0.344817   \n",
      "282 -1.969961     -0.180032     -0.694441    0.103266        4.5   -0.909642   \n",
      "261 -0.203128      1.819845      2.364935    1.461918        5.5    1.481450   \n",
      "205 -0.707938     -1.179971      0.488518   -0.023370        6.5   -0.344817   \n",
      "134  1.311300      0.819906      0.080601   -0.292740        6.0    1.462623   \n",
      "94   1.058895      0.819906      0.406935    0.704249        6.5    2.272205   \n",
      "449  0.301681     -1.179971     -0.082566    0.481027        6.0    0.220008   \n",
      "116  0.554086     -0.180032     -0.327316   -0.587866        4.5    0.671868   \n",
      "88  -0.707938      0.819906     -0.735232   -0.695184        4.5   -0.646057   \n",
      "298  0.049276     -0.180032     -0.490482   -0.625427        4.5   -1.079089   \n",
      "248  1.816109     -0.180032     -0.245732    1.667969        6.5    0.540075   \n",
      "..        ...           ...           ...         ...        ...         ...   \n",
      "423  1.816109      1.819845     -0.572066   -0.300252        4.5    1.048418   \n",
      "318  0.806490     -1.179971     -0.164149   -0.065225        6.0   -0.005922   \n",
      "74   1.058895      1.819845     -0.572066   -0.050200        5.0    1.726208   \n",
      "292  1.311300      0.819906     -0.694441   -0.620061        4.0   -1.079089   \n",
      "430  0.554086      0.819906     -0.531274   -0.566402        5.0    0.314146   \n",
      "47   1.311300      1.819845     -0.816816   -0.684452        4.0   -0.928469   \n",
      "445  0.049276     -0.180032      0.080601   -0.514889        5.0    0.408283   \n",
      "236 -1.717556     -1.179971     -0.735232   -0.408644        5.0   -1.079089   \n",
      "145  1.816109      1.819845     -0.735232   -0.151079        4.5    0.201181   \n",
      "83   0.554086     -0.180032     -0.408899   -0.459083        5.5   -0.062404   \n",
      "443  1.563704      0.819906     -0.327316    0.110778        5.0    0.766005   \n",
      "312 -0.455533     -0.180032     -0.082566   -0.308838        4.5    0.427110   \n",
      "186 -0.203128     -1.179971     -0.816816   -0.684452        4.5   -1.079089   \n",
      "214 -0.455533     -1.179971      2.772852    2.354808        9.0    2.140413   \n",
      "344 -0.203128     -1.179971     -0.490482    0.602297        5.5   -0.514264   \n",
      "230 -0.707938      1.819845     -0.245732    0.527174        5.0   -0.476609   \n",
      "187  0.301681     -1.179971     -0.653649   -0.592158        5.5   -1.079089   \n",
      "455  1.311300      0.819906     -0.327316   -0.070590        5.0   -0.231852   \n",
      "30   0.806490      0.819906     -0.653649   -0.621134        5.0    1.443795   \n",
      "313  0.301681      0.819906     -0.490482   -0.479474        5.0    0.389456   \n",
      "54  -0.455533      0.819906     -0.490482   -0.669428        4.5   -1.079089   \n",
      "148 -1.717556      0.819906     -0.490482   -0.450498        4.5   -0.062404   \n",
      "264 -0.960342      0.819906      1.549101    0.884544        6.0    0.897798   \n",
      "453  0.049276     -1.179971      0.080601   -0.396839        5.5   -0.043577   \n",
      "442  0.554086      0.819906     -0.082566   -0.456937        5.0    0.841315   \n",
      "110 -0.707938      0.819906      1.141185   -0.332448        6.0   -1.079089   \n",
      "409 -0.707938     -0.180032     -0.408899   -0.686599        5.0   -0.363644   \n",
      "386  0.049276      0.819906      1.385935    0.090387        6.5    0.502420   \n",
      "24  -0.455533      0.819906     -0.490482   -0.217617        4.5   -1.041434   \n",
      "226  0.049276     -1.179971      0.733268    1.371770        8.0   -0.062404   \n",
      "\n",
      "     region  new_foreign  age_cat  club_id  big_club  new_signing  \n",
      "265     2.0            0        4       12  1.512575            0  \n",
      "412     4.0            0        1       18 -0.659690            1  \n",
      "320     2.0            0        3       14 -0.659690            0  \n",
      "332     2.0            0        4       15 -0.659690            0  \n",
      "333     2.0            0        4       15 -0.659690            0  \n",
      "242     1.0            0        2       11  1.512575            0  \n",
      "410     2.0            0        3       18 -0.659690            1  \n",
      "202     1.0            0        1        9 -0.659690            0  \n",
      "327     1.0            0        1       14 -0.659690            0  \n",
      "119     2.0            0        4        6 -0.659690            0  \n",
      "306     1.0            0        4       14 -0.659690            0  \n",
      "460     4.0            0        3       20 -0.659690            0  \n",
      "163     2.0            0        3        8 -0.659690            0  \n",
      "149     4.0            0        4        7 -0.659690            1  \n",
      "241     3.0            0        4       11  1.512575            0  \n",
      "223     2.0            0        3       10  1.512575            1  \n",
      "418     2.0            0        3       18 -0.659690            0  \n",
      "335     2.0            0        3       15 -0.659690            0  \n",
      "103     2.0            0        4        5  1.512575            0  \n",
      "362     4.0            0        3       16 -0.659690            0  \n",
      "282     2.0            0        1       12  1.512575            0  \n",
      "261     2.0            0        3       12  1.512575            0  \n",
      "205     4.0            0        2        9 -0.659690            1  \n",
      "134     1.0            0        5        7 -0.659690            0  \n",
      "94      1.0            0        4        5  1.512575            0  \n",
      "449     1.0            0        4       20 -0.659690            0  \n",
      "116     2.0            0        4        6 -0.659690            0  \n",
      "88      1.0            0        2        4 -0.659690            0  \n",
      "298     1.0            0        3       13 -0.659690            0  \n",
      "248     4.0            0        6       11  1.512575            0  \n",
      "..      ...          ...      ...      ...       ...          ...  \n",
      "423     1.0            0        6       19 -0.659690            0  \n",
      "318     2.0            0        4       14 -0.659690            0  \n",
      "74      1.0            0        4        4 -0.659690            0  \n",
      "292     2.0            0        5       13 -0.659690            0  \n",
      "430     4.0            0        4       19 -0.659690            1  \n",
      "47      4.0            0        5        2 -0.659690            0  \n",
      "445     4.0            0        3       20 -0.659690            0  \n",
      "236     1.0            0        1       10  1.512575            0  \n",
      "145     2.0            0        6        7 -0.659690            1  \n",
      "83      2.0            0        4        4 -0.659690            1  \n",
      "443     2.0            0        5       20 -0.659690            1  \n",
      "312     2.0            0        3       14 -0.659690            0  \n",
      "186     2.0            0        3        8 -0.659690            0  \n",
      "214     3.0            0        3       10  1.512575            0  \n",
      "344     2.0            0        3       15 -0.659690            0  \n",
      "230     2.0            0        2       10  1.512575            0  \n",
      "187     2.0            0        4        8 -0.659690            0  \n",
      "455     3.0            0        5       20 -0.659690            0  \n",
      "30      1.0            0        4        2 -0.659690            0  \n",
      "313     4.0            0        4       14 -0.659690            0  \n",
      "54      1.0            0        3        3 -0.659690            0  \n",
      "148     1.0            0        1        7 -0.659690            0  \n",
      "264     4.0            0        2       12  1.512575            1  \n",
      "453     4.0            0        3       20 -0.659690            1  \n",
      "442     4.0            0        4       20 -0.659690            0  \n",
      "110     2.0            1        2        5  1.512575            0  \n",
      "409     2.0            0        2       18 -0.659690            0  \n",
      "386     1.0            0        3       17  1.512575            0  \n",
      "24      1.0            0        3        1  1.512575            0  \n",
      "226     1.0            0        3       10  1.512575            0  \n",
      "\n",
      "[92 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "        self.activation_function = lambda x : 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def train(self, features, targets):\n",
    "        ''' Train the network on batch of features and targets. \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            \n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "        \n",
    "        '''\n",
    "        n_records = features.shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        for X, y in zip(features, targets):\n",
    "            ### Forward pass ###\n",
    "            hidden_inputs = np.dot(X, self.weights_input_to_hidden)\n",
    "            hidden_outputs = self.activation_function(hidden_inputs)\n",
    "            final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output)\n",
    "            # since the last layer just passes on its value, we don't have to apply the sigmoid here.\n",
    "            final_outputs = final_inputs\n",
    "            \n",
    "            ### Backward pass ###\n",
    "            error = y - final_outputs\n",
    "            # The derivative of the activation function y=x is 1\n",
    "            output_error_term = error * 1.0\n",
    "            hidden_error = np.dot(self.weights_hidden_to_output, error) \n",
    "            # Backpropagated error terms\n",
    "            hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)\n",
    "            # Weight step (input to hidden)\n",
    "            delta_weights_i_h += hidden_error_term * X[:,None]\n",
    "            # Weight step (hidden to output)\n",
    "            delta_weights_h_o += output_error_term * hidden_outputs[:,None]\n",
    "        # Weights update\n",
    "        self.weights_hidden_to_output += self.lr*delta_weights_h_o/n_records\n",
    "        self.weights_input_to_hidden += self.lr*delta_weights_i_h/n_records\n",
    "        \n",
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "        # Forward pass\n",
    "        hidden_inputs =  np.dot(features, self.weights_input_to_hidden)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output)\n",
    "        final_outputs = final_inputs \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-45e2de388325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Go through a random batch of 128 records from the training data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cnt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_targets' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "### Set the hyperparameters here ###\n",
    "iterations = 3000\n",
    "learning_rate = 1.1\n",
    "hidden_nodes = 15\n",
    "output_nodes = 1\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for ii in range(iterations):\n",
    "    # Go through a random batch of 128 records from the training data set\n",
    "    batch = np.random.choice(train_features.index, size=128)\n",
    "    X, y = train_features.ix[batch].values, train_targets.ix[batch]['cnt']\n",
    "                             \n",
    "    network.train(X, y)\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features).T, train_targets['cnt'].values)\n",
    "    val_loss = MSE(network.run(val_features).T, val_targets['cnt'].values)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. 28.]\n",
      " [ 1. 28.]\n",
      " [ 4. 35.]\n",
      " [ 1. 28.]\n",
      " [ 3. 31.]\n",
      " [ 3. 22.]\n",
      " [ 1. 30.]\n",
      " [ 3. 31.]\n",
      " [ 3. 25.]\n",
      " [ 1. 21.]\n",
      " [ 2. 24.]\n",
      " [ 2. 23.]\n",
      " [ 2. 25.]\n",
      " [ 2. 26.]\n",
      " [ 2. 26.]\n",
      " [ 3. 26.]\n",
      " [ 3. 27.]\n",
      " [ 2. 32.]\n",
      " [ 1. 26.]\n",
      " [ 3. 21.]\n",
      " [ 2. 25.]\n",
      " [ 1. 28.]\n",
      " [ 4. 24.]\n",
      " [ 4. 28.]\n",
      " [ 3. 25.]\n",
      " [ 3. 32.]\n",
      " [ 3. 24.]\n",
      " [ 1. 26.]\n",
      " [ 1. 25.]\n",
      " [ 1. 34.]\n",
      " [ 3. 30.]\n",
      " [ 4. 37.]\n",
      " [ 3. 26.]\n",
      " [ 1. 27.]\n",
      " [ 3. 26.]\n",
      " [ 1. 23.]\n",
      " [ 3. 32.]\n",
      " [ 1. 24.]\n",
      " [ 2. 27.]\n",
      " [ 1. 30.]\n",
      " [ 1. 25.]\n",
      " [ 3. 22.]\n",
      " [ 2. 27.]\n",
      " [ 2. 30.]\n",
      " [ 1. 21.]\n",
      " [ 2. 20.]\n",
      " [ 1. 21.]\n",
      " [ 4. 32.]\n",
      " [ 1. 29.]\n",
      " [ 3. 24.]\n",
      " [ 3. 23.]\n",
      " [ 4. 30.]\n",
      " [ 4. 32.]\n",
      " [ 4. 25.]\n",
      " [ 3. 25.]\n",
      " [ 3. 25.]\n",
      " [ 3. 31.]\n",
      " [ 1. 36.]\n",
      " [ 3. 29.]\n",
      " [ 3. 33.]\n",
      " [ 3. 24.]\n",
      " [ 3. 30.]\n",
      " [ 1. 25.]\n",
      " [ 2. 27.]\n",
      " [ 2. 29.]\n",
      " [ 2. 34.]\n",
      " [ 2. 23.]\n",
      " [ 1. 25.]\n",
      " [ 2. 26.]\n",
      " [ 1. 27.]\n",
      " [ 2. 26.]\n",
      " [ 1. 33.]\n",
      " [ 1. 30.]\n",
      " [ 1. 28.]\n",
      " [ 4. 31.]\n",
      " [ 1. 27.]\n",
      " [ 1. 26.]\n",
      " [ 3. 27.]\n",
      " [ 3. 31.]\n",
      " [ 3. 28.]\n",
      " [ 1. 27.]\n",
      " [ 2. 25.]\n",
      " [ 2. 28.]\n",
      " [ 2. 29.]\n",
      " [ 2. 33.]\n",
      " [ 2. 28.]\n",
      " [ 1. 26.]\n",
      " [ 2. 25.]\n",
      " [ 3. 24.]\n",
      " [ 2. 27.]\n",
      " [ 3. 26.]\n",
      " [ 2. 35.]\n",
      " [ 1. 26.]\n",
      " [ 1. 28.]\n",
      " [ 3. 31.]\n",
      " [ 3. 26.]\n",
      " [ 3. 27.]\n",
      " [ 1. 29.]\n",
      " [ 4. 25.]\n",
      " [ 3. 30.]\n",
      " [ 2. 30.]\n",
      " [ 1. 28.]\n",
      " [ 2. 26.]\n",
      " [ 2. 28.]\n",
      " [ 2. 26.]\n",
      " [ 4. 35.]\n",
      " [ 1. 23.]\n",
      " [ 3. 22.]\n",
      " [ 3. 21.]\n",
      " [ 1. 34.]\n",
      " [ 3. 24.]\n",
      " [ 2. 22.]\n",
      " [ 1. 24.]\n",
      " [ 1. 26.]\n",
      " [ 1. 26.]\n",
      " [ 3. 26.]\n",
      " [ 2. 29.]\n",
      " [ 4. 30.]\n",
      " [ 1. 31.]\n",
      " [ 2. 31.]\n",
      " [ 3. 27.]\n",
      " [ 3. 28.]\n",
      " [ 3. 30.]\n",
      " [ 3. 36.]\n",
      " [ 3. 24.]\n",
      " [ 3. 27.]\n",
      " [ 2. 26.]\n",
      " [ 1. 29.]\n",
      " [ 1. 24.]\n",
      " [ 1. 29.]\n",
      " [ 3. 27.]\n",
      " [ 2. 21.]\n",
      " [ 4. 38.]\n",
      " [ 1. 23.]\n",
      " [ 3. 32.]\n",
      " [ 3. 28.]\n",
      " [ 3. 32.]\n",
      " [ 1. 29.]\n",
      " [ 3. 24.]\n",
      " [ 3. 34.]\n",
      " [ 4. 23.]\n",
      " [ 4. 27.]\n",
      " [ 2. 27.]\n",
      " [ 1. 31.]\n",
      " [ 3. 26.]\n",
      " [ 4. 34.]\n",
      " [ 2. 36.]\n",
      " [ 2. 19.]\n",
      " [ 3. 20.]\n",
      " [ 1. 28.]\n",
      " [ 2. 27.]\n",
      " [ 3. 27.]\n",
      " [ 2. 26.]\n",
      " [ 1. 30.]\n",
      " [ 1. 20.]\n",
      " [ 1. 19.]\n",
      " [ 3. 22.]\n",
      " [ 3. 20.]\n",
      " [ 2. 24.]\n",
      " [ 1. 24.]\n",
      " [ 1. 22.]\n",
      " [ 4. 21.]\n",
      " [ 4. 28.]\n",
      " [ 3. 27.]\n",
      " [ 3. 28.]\n",
      " [ 3. 25.]\n",
      " [ 3. 26.]\n",
      " [ 3. 30.]\n",
      " [ 3. 21.]\n",
      " [ 3. 35.]\n",
      " [ 3. 27.]\n",
      " [ 3. 26.]\n",
      " [ 2. 26.]\n",
      " [ 1. 26.]\n",
      " [ 2. 28.]\n",
      " [ 2. 21.]\n",
      " [ 1. 24.]\n",
      " [ 2. 25.]\n",
      " [ 2. 35.]\n",
      " [ 1. 24.]\n",
      " [ 1. 26.]\n",
      " [ 1. 25.]\n",
      " [ 1. 25.]\n",
      " [ 1. 20.]\n",
      " [ 3. 26.]\n",
      " [ 1. 27.]\n",
      " [ 1. 26.]\n",
      " [ 1. 28.]\n",
      " [ 1. 22.]\n",
      " [ 1. 30.]\n",
      " [ 1. 26.]\n",
      " [ 4. 30.]\n",
      " [ 3. 31.]\n",
      " [ 2. 27.]\n",
      " [ 3. 32.]\n",
      " [ 3. 30.]\n",
      " [ 1. 29.]\n",
      " [ 3. 24.]\n",
      " [ 2. 27.]\n",
      " [ 3. 33.]\n",
      " [ 1. 31.]\n",
      " [ 2. 20.]\n",
      " [ 1. 21.]\n",
      " [ 2. 22.]\n",
      " [ 2. 28.]\n",
      " [ 1. 24.]\n",
      " [ 3. 30.]\n",
      " [ 1. 30.]\n",
      " [ 3. 20.]\n",
      " [ 2. 25.]\n",
      " [ 4. 29.]\n",
      " [ 3. 26.]\n",
      " [ 2. 29.]\n",
      " [ 1. 25.]\n",
      " [ 1. 25.]\n",
      " [ 1. 25.]\n",
      " [ 2. 26.]\n",
      " [ 2. 31.]\n",
      " [ 1. 29.]\n",
      " [ 3. 26.]\n",
      " [ 4. 29.]\n",
      " [ 3. 28.]\n",
      " [ 2. 23.]\n",
      " [ 3. 25.]\n",
      " [ 1. 22.]\n",
      " [ 2. 27.]\n",
      " [ 1. 27.]\n",
      " [ 2. 30.]\n",
      " [ 3. 31.]\n",
      " [ 3. 27.]\n",
      " [ 4. 24.]\n",
      " [ 3. 18.]\n",
      " [ 3. 25.]\n",
      " [ 1. 17.]\n",
      " [ 2. 21.]\n",
      " [ 3. 20.]\n",
      " [ 1. 20.]\n",
      " [ 1. 25.]\n",
      " [ 1. 24.]\n",
      " [ 1. 19.]\n",
      " [ 1. 26.]\n",
      " [ 1. 29.]\n",
      " [ 1. 22.]\n",
      " [ 3. 27.]\n",
      " [ 1. 31.]\n",
      " [ 1. 21.]\n",
      " [ 3. 29.]\n",
      " [ 3. 31.]\n",
      " [ 2. 34.]\n",
      " [ 2. 32.]\n",
      " [ 4. 34.]\n",
      " [ 1. 20.]\n",
      " [ 3. 23.]\n",
      " [ 3. 31.]\n",
      " [ 1. 20.]\n",
      " [ 2. 26.]\n",
      " [ 2. 32.]\n",
      " [ 2. 27.]\n",
      " [ 4. 23.]\n",
      " [ 1. 22.]\n",
      " [ 1. 24.]\n",
      " [ 4. 26.]\n",
      " [ 3. 31.]\n",
      " [ 2. 24.]\n",
      " [ 3. 23.]\n",
      " [ 1. 29.]\n",
      " [ 3. 27.]\n",
      " [ 2. 27.]\n",
      " [ 1. 21.]\n",
      " [ 3. 27.]\n",
      " [ 1. 19.]\n",
      " [ 1. 28.]\n",
      " [ 3. 27.]\n",
      " [ 1. 24.]\n",
      " [ 3. 25.]\n",
      " [ 3. 27.]\n",
      " [ 2. 29.]\n",
      " [ 3. 22.]\n",
      " [ 2. 35.]\n",
      " [ 2. 32.]\n",
      " [ 4. 30.]\n",
      " [ 3. 19.]\n",
      " [ 2. 19.]\n",
      " [ 4. 21.]\n",
      " [ 3. 23.]\n",
      " [ 4. 31.]\n",
      " [ 4. 26.]\n",
      " [ 3. 24.]\n",
      " [ 3. 27.]\n",
      " [ 3. 27.]\n",
      " [ 3. 25.]\n",
      " [ 3. 25.]\n",
      " [ 3. 32.]\n",
      " [ 3. 26.]\n",
      " [ 3. 24.]\n",
      " [ 2. 27.]\n",
      " [ 2. 25.]\n",
      " [ 2. 30.]\n",
      " [ 2. 27.]\n",
      " [ 1. 25.]\n",
      " [ 1. 28.]\n",
      " [ 1. 21.]\n",
      " [ 1. 26.]\n",
      " [ 1. 23.]\n",
      " [ 1. 22.]\n",
      " [ 1. 34.]\n",
      " [ 4. 29.]\n",
      " [ 1. 23.]\n",
      " [ 3. 27.]\n",
      " [ 1. 28.]\n",
      " [ 3. 25.]\n",
      " [ 2. 22.]\n",
      " [ 2. 25.]\n",
      " [ 3. 28.]\n",
      " [ 2. 32.]\n",
      " [ 3. 26.]\n",
      " [ 1. 28.]\n",
      " [ 3. 23.]\n",
      " [ 1. 30.]\n",
      " [ 1. 23.]\n",
      " [ 2. 26.]\n",
      " [ 2. 21.]\n",
      " [ 1. 25.]\n",
      " [ 2. 22.]\n",
      " [ 3. 21.]\n",
      " [ 1. 20.]\n",
      " [ 2. 28.]\n",
      " [ 3. 21.]\n",
      " [ 3. 21.]\n",
      " [ 2. 27.]\n",
      " [ 1. 28.]\n",
      " [ 4. 34.]\n",
      " [ 3. 28.]\n",
      " [ 1. 30.]\n",
      " [ 3. 29.]\n",
      " [ 1. 25.]\n",
      " [ 1. 36.]\n",
      " [ 2. 33.]\n",
      " [ 2. 31.]\n",
      " [ 3. 32.]\n",
      " [ 3. 32.]\n",
      " [ 1. 29.]\n",
      " [ 1. 20.]\n",
      " [ 3. 25.]\n",
      " [ 1. 26.]\n",
      " [ 3. 32.]\n",
      " [ 1. 23.]\n",
      " [ 2. 24.]\n",
      " [ 4. 24.]\n",
      " [ 2. 31.]\n",
      " [ 3. 18.]\n",
      " [ 1. 27.]\n",
      " [ 1. 32.]\n",
      " [ 4. 32.]\n",
      " [ 2. 27.]\n",
      " [ 3. 23.]\n",
      " [ 3. 28.]\n",
      " [ 1. 32.]\n",
      " [ 3. 28.]\n",
      " [ 3. 29.]\n",
      " [ 2. 25.]\n",
      " [ 2. 28.]\n",
      " [ 1. 25.]\n",
      " [ 1. 24.]\n",
      " [ 2. 34.]\n",
      " [ 3. 22.]\n",
      " [ 3. 34.]\n",
      " [ 1. 26.]\n",
      " [ 2. 23.]\n",
      " [ 1. 27.]\n",
      " [ 3. 24.]\n",
      " [ 1. 29.]\n",
      " [ 1. 21.]\n",
      " [ 4. 28.]\n",
      " [ 2. 28.]\n",
      " [ 1. 19.]\n",
      " [ 2. 21.]\n",
      " [ 1. 23.]\n",
      " [ 1. 25.]\n",
      " [ 1. 25.]\n",
      " [ 4. 30.]\n",
      " [ 3. 30.]\n",
      " [ 3. 28.]\n",
      " [ 2. 26.]\n",
      " [ 2. 23.]\n",
      " [ 3. 24.]\n",
      " [ 3. 27.]\n",
      " [ 2. 30.]\n",
      " [ 1. 23.]\n",
      " [ 3. 26.]\n",
      " [ 2. 27.]\n",
      " [ 2. 21.]\n",
      " [ 1. 25.]\n",
      " [ 4. 33.]\n",
      " [ 1. 22.]\n",
      " [ 3. 24.]\n",
      " [ 2. 29.]\n",
      " [ 1. 29.]\n",
      " [ 4. 36.]\n",
      " [ 3. 33.]\n",
      " [ 3. 32.]\n",
      " [ 3. 30.]\n",
      " [ 1. 30.]\n",
      " [ 3. 31.]\n",
      " [ 2. 27.]\n",
      " [ 3. 27.]\n",
      " [ 2. 32.]\n",
      " [ 1. 26.]\n",
      " [ 1. 27.]\n",
      " [ 2. 24.]\n",
      " [ 3. 26.]\n",
      " [ 3. 28.]\n",
      " [ 1. 21.]\n",
      " [ 3. 30.]\n",
      " [ 2. 22.]\n",
      " [ 1. 30.]\n",
      " [ 4. 30.]\n",
      " [ 3. 26.]\n",
      " [ 1. 25.]\n",
      " [ 2. 22.]\n",
      " [ 3. 37.]\n",
      " [ 1. 27.]\n",
      " [ 1. 26.]\n",
      " [ 4. 34.]\n",
      " [ 1. 27.]\n",
      " [ 3. 27.]\n",
      " [ 2. 32.]\n",
      " [ 2. 31.]\n",
      " [ 3. 29.]\n",
      " [ 2. 27.]\n",
      " [ 3. 29.]\n",
      " [ 1. 27.]\n",
      " [ 2. 30.]\n",
      " [ 1. 28.]\n",
      " [ 1. 28.]\n",
      " [ 1. 18.]\n",
      " [ 2. 19.]\n",
      " [ 4. 34.]\n",
      " [ 3. 26.]\n",
      " [ 1. 29.]\n",
      " [ 1. 24.]\n",
      " [ 1. 27.]\n",
      " [ 3. 29.]\n",
      " [ 3. 33.]\n",
      " [ 1. 27.]\n",
      " [ 2. 27.]\n",
      " [ 2. 30.]\n",
      " [ 4. 30.]\n",
      " [ 3. 33.]\n",
      " [ 1. 28.]\n",
      " [ 4. 30.]\n",
      " [ 3. 27.]\n",
      " [ 2. 25.]\n",
      " [ 1. 27.]\n",
      " [ 3. 29.]\n",
      " [ 3. 32.]\n",
      " [ 2. 21.]\n",
      " [ 3. 23.]\n",
      " [ 3. 23.]\n",
      " [ 1. 21.]\n",
      " [ 1. 27.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# This imports a csv from numpy\n",
    "csv = np.genfromtxt ('epldata_final.csv', delimiter=\",\")\n",
    "# This imports a column from the csv and takes from the 2nd element in the column\n",
    "second = csv[1:,4]\n",
    "third = csv[1:,2]\n",
    "# This concatonates the columns so it stacks together\n",
    "test_2D = np.column_stack((second, third))\n",
    "\n",
    "print(test_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import unittest\n",
    "\n",
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])\n",
    "test_w_i_h = np.array([[0.1, -0.2],\n",
    "                       [0.4, 0.5],\n",
    "                       [-0.3, 0.2]])\n",
    "test_w_h_o = np.array([[0.3],\n",
    "                       [-0.1]])\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for data loading\n",
    "    ##########\n",
    "\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for network functionality\n",
    "    ##########\n",
    "\n",
    "    def test_activation(self):\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        # Test that the activation function is a sigmoid\n",
    "        self.assertTrue(np.all(network.activation_function(0.5) == 1/(1+np.exp(-0.5))))\n",
    "\n",
    "    def test_train(self):\n",
    "        # Test that weights are updated correctly on training\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "        \n",
    "        network.train(inputs, targets)\n",
    "        self.assertTrue(np.allclose(network.weights_hidden_to_output, \n",
    "                                    np.array([[ 0.37275328], \n",
    "                                              [-0.03172939]])))\n",
    "        self.assertTrue(np.allclose(network.weights_input_to_hidden,\n",
    "                                    np.array([[ 0.10562014, -0.20185996], \n",
    "                                              [0.39775194, 0.50074398], \n",
    "                                              [-0.29887597, 0.19962801]])))\n",
    "\n",
    "    def test_run(self):\n",
    "        # Test correctness of run method\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "\n",
    "        self.assertTrue(np.allclose(network.run(inputs), 0.09998924))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestMethods())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-45e2de388325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mN_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.10781473e-16 2.92908623e-17]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler().fit(test_2D)\n",
    "# Applying transformer to training dataPython\n",
    "\n",
    "X_train_scaled = scaler.transform(test_2D)\n",
    " \n",
    "print(X_train_scaled.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.77777778, 33.05555556],\n",
       "       [ 1.95698925, 21.2688172 ],\n",
       "       [ 2.09836066, 25.72677596],\n",
       "       [ 2.11504425, 29.12389381]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#               [4, 2], [4, 4], [4, 0]])\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(test_2D)\n",
    "kmeans.labels_\n",
    "\n",
    "# kmeans.predict([[4, 23], [21, 21]])\n",
    "\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fot the above clustering algorithm you should sort the features as below\n",
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn#step-5\n",
    "\n",
    "# To do:\n",
    "# numpy arrays figure out and use to create 2d array :/\n",
    "# remove feature with letter resave features in dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
